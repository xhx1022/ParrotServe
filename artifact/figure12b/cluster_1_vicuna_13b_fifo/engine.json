{
    "engine_name": "vicuna-13b-v1.3_local",
    "model": "lmsys/vicuna-13b-v1.3",
    "host": "localhost",
    "port": 9001,
    "engine_type": "builtin",
    "random_seed": 0,
    "tokenizer": "hf-internal-testing/llama-tokenizer",
    "fill_chunk_size": -1,
    "threads_capacity": 9999999,
    "instance": {
        "max_seq_len": 4096,
        "block_size": 16,
        "num_kv_cache_blocks": 4000,
        "attn_func": "xformers_fill_vllm_paged_attention_generate"
    },
    "scheduler": {
        "max_batch_size": 999999,
        "max_num_batched_tokens": 2560,
        "max_total_tokens": 4096,
        "policy": "fifo_v2"
    },
    "os": {
        "host": "localhost",
        "port": 9000
    }
}